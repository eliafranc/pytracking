# Pytracking

Slightly modified version of the [pytracking](https://github.com/visionml/pytracking) repository.
Make sure to clone this repository with the  **--recurse_submodules** flag  and initialize the submodules:

```bash
git clone --recurse-submodules <link-to-repo>
cd pytracking
git submodule update --init --recursive

```

In order to use use any of the trackers, it is necessary to build the pytracking docker container.
Follow the steps described in the [README.md](docker/README.md) and find the mounted project repository in the docker root directory, once it is running.

### Before Running a Tracker

To finalize the setup of pytracking make sure to run the [install script](install.sh). The install script downloads the
RTS and ToMP network models. If other trackers would like to be installed, make sure to place them in the `pytracking/networks/` folder.
The install script also sets up the environment by running the _create_default_local_file()_ in [pytracking](pytracking/evaluation/environment.py) and [lts](ltr/admin/environment.py) which create _local.py_ files which describe where the pretrained networks are stored for example.

```bash
./install.sh
```

After running the install script, make sure that the paths in the _local.py_ files for [pytracking](pytracking/evaluation/local.py) and [ltr](ltr/admin/local.py) are set correctly, according to your environment. An example how your _local.py_ file should look in the `pytracking/` directory can be found below:

<p align="center">
  <img src="../assets/local_file.png" width="400"/>
</p>

### Running the RTS / ToMP tracker
The python scripts that are of relevance are located in the `pytracking/` folder.

#### run_tracker_on_tensor.py
This function can be used to run a tracker evaluation for all input representations presented in our work. To start an evaluation simply run `python3 run_tracker_on_tensor.py <tracker> <tracker_params>` where `<tracker>` can be "rts" or "tomp" and `<tracker_parmas>` is "rts50" and "tomp50" respectively. The evaluation goes over every sequence in our dataset and writes all tracking and segmentation results to the directory defined in [the local.py file](pytracking/evaluation/local.py).

#### run_tensor.py
This function can be used to run one of the trackers for a single sequence. Use the function by running the following command: `python3 run_tensor.py <tracker> <tracker_params> <sequence>` where `<sequence>` is the name of the sequence you would like to run a tracker on (e.g. "2024_01_10_112814_drone_002"). Make sure the constant variable `PATH_TO_DATA` in line 11 is set to correct root directory of the dataset. You can run different input configurations by adjusting  the optional arguments `--delta_t` and `--rgb_only` where setting the latter runs the tracker on RGB only data and the former can be used to run different time interals over which events should be accumulated (in ms). 

Running `run_tensor.py` with the `--visualize` flag will save each frame with plotted bounding boxes while running the command with flag `--save_results` will also save the bounding box predictions. For debugging purposes it is also possible to run the command with the `--debug` argument where no results are saved but we can inspect details about the tracking in the visdom server that is running on `http://localhost:8097`. Make sure the server is up beforehand by running `python3 -m visdom.server`.


#### run_evaluation.py
The `run_evaluation.py` script evaluates all results generated by the `run_tracker_on_tensor.py`. Run `python3 run_evaluation.py <tracker> <tracker_params> <report_name>` where `<report_name>` is the name of the directory that is being generated which holds all of the evaluation results. We implemented a [dataset class for our event-based drone dataset](pytracking/evaluation/evdronedataset.py). The `run_evaluation.py` script gets the sequence paths and ground truths from this dataset class in order to evaluate the tracking results.
